# Data Wrangling
## Acquisation and Cleaning the dataset for analysis
 Data Cleaning plays an essential role. Data Cleaning is the process of retaining only the crucial information from the output so that only relevant features are sent as input to the machine learning model.
 Some common techniques used for data cleaning include identifying and handling missing values, removing duplicates, correcting inconsistent values, and handling outliers.
## Creating a Basic Data Cleaning Pipeline in Python

## Loading the CSV file: 
The CSV file is loaded as a data frame using the pandas module in Python.
## Preprocessing the Data: 
The data has multiple attributes and mostly these are not in a format that Machine Learning modules can understand. 
## Removing duplicates: 
Duplicate rows in a dataset can cause errors or bias in analysis, so it’s important to remove them.
## Correcting inconsistent data: 
Inconsistent data can arise due to errors in data entry or data integration. 
## Handling outliers: 
Outliers can skew analysis, so it’s important to handle them appropriately. 
## Formatting data: 
Data may need to be formatted to meet the requirements of the analysis. 
## Handling missing values: 
Missing values can cause problems with analysis, so it’s important to handle them appropriately. 
## Removal of all Above Unwanted Observations
This includes deleting duplicate/ redundant or irrelevant values from your dataset. Duplicate observations most frequently arise during data collection and Irrelevant observations are those that don’t actually fit the specific problem. 
## Advantages of Data Cleaning in Machine Learning:
Improved model performance: Removal of errors, inconsistencies, and irrelevant data, helps the model to better learn from the data.
Increased accuracy: Helps ensure that the data is accurate, consistent, and free of errors.
Better representation of the data: Data cleaning allows the data to be transformed into a format that better represents the underlying relationships and patterns in the data.
Improved data quality: Improve the quality of the data, making it more reliable and accurate.
Improved data security: Helps to identify and remove sensitive or confidential information that could compromise data security.
## Conclusion
 Four different steps in data cleaning to make the data more reliable and to produce good results. After properly completing the Data Cleaning steps, I have a robust dataset that avoids many of the most common pitfalls. In summary, data cleaning is a crucial step in the data science pipeline that involves identifying and correcting errors, inconsistencies, and inaccuracies in the data to improve its quality and usability.
